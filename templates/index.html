<!doctype html>
<html lang="en">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width,initial-scale=1" />
  <title>Face Detect — Single Page</title>
  <style>
    :root{--bg:#0f1724;--card:#0b1220;--accent:#06b6d4;--muted:#94a3b8;--glass:rgba(255,255,255,0.04)}
    html,body{height:100%;margin:0;font-family:Inter,ui-sans-serif,system-ui,-apple-system,Segoe UI,Roboto,'Helvetica Neue',Arial}
    body{background:linear-gradient(180deg,#071126 0%, #071629 60%);color:#e6eef6;display:flex;align-items:center;justify-content:center;padding:28px}
    .card{width:920px;max-width:100%;background:linear-gradient(180deg, rgba(255,255,255,0.02), rgba(255,255,255,0.01));border-radius:12px;padding:18px;box-shadow:0 10px 30px rgba(2,6,23,0.6);display:grid;grid-template-columns:640px 1fr;gap:18px}

    .video-wrap{position:relative;border-radius:8px;overflow:hidden;background:var(--glass);display:flex;align-items:center;justify-content:center;height:480px}
    video{display:block;width:100%;height:100%;object-fit:cover}
    canvas#overlay{position:absolute;left:0;top:0;pointer-events:none}

    .controls{display:flex;flex-direction:column;gap:12px;padding:8px}
    h1{font-size:18px;margin:0 0 6px 0}
    p.lead{margin:0;color:var(--muted);font-size:13px}

    .btns{display:flex;gap:8px;flex-wrap:wrap;margin-top:8px}
    button{background:transparent;border:1px solid rgba(255,255,255,0.08);color:inherit;padding:8px 12px;border-radius:8px;cursor:pointer;font-weight:600}
    button.primary{background:linear-gradient(90deg, var(--accent), #7c3aed);border:0}
    button.danger{background:transparent;border:1px solid rgba(255,90,90,0.15)}

    .status{font-size:13px;margin-top:8px;color:var(--muted)}
    .small{font-size:12px;color:var(--muted)}

    .info{background:rgba(255,255,255,0.02);padding:12px;border-radius:8px;font-size:13px}
    .footer{margin-top:auto;font-size:12px;color:var(--muted)}

    @media (max-width:900px){.card{grid-template-columns:1fr;gap:12px}.video-wrap{height:360px}}
  </style>
</head>
<body>
  <div class="card">
    <div>
      <div class="video-wrap">
        <video id="video" autoplay muted playsinline></video>
        <canvas id="overlay"></canvas>
      </div>
    </div>

    <div class="controls">
      <div>
        <h1>Face Detect — Single Page</h1>
        <p class="lead">Uses TensorFlow.js + BlazeFace to detect faces from your webcam. Runs fully in the browser (no server required).</p>
      </div>

      <div class="btns">
        <button id="start" class="primary">Start Camera</button>
        <button id="stop">Stop Camera</button>
        <button id="snapshot">Snapshot</button>
        <button id="toggleBoxes">Toggle Boxes</button>
        <button id="download" class="primary">Download Snapshot</button>
      </div>

      <div class="status" id="status">Status: idle — models not loaded</div>

      <div class="info">
        <strong>Notes</strong>
        <ul style="margin:6px 0 0 18px;padding:0">
          <li>Allow camera access when prompted.</li>
          <li>Detection runs in real-time; performance depends on your device.</li>
          <li>If nothing appears, try a different browser (Chrome/Edge recommended).</li>
        </ul>
      </div>

      <div class="footer">Built with <a href="https://www.tensorflow.org/js" target="_blank" style="color:inherit">TensorFlow.js</a> + <a href="https://github.com/tensorflow/tfjs-models/tree/master/blazeface" target="_blank" style="color:inherit">BlazeFace</a></div>
    </div>
  </div>

  <!-- TensorFlow.js and BlazeFace from CDN -->
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@3.21.0/dist/tf.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/blazeface@0.0.7/dist/blazeface.min.js"></script>

  <script>
    // Elements
    const video = document.getElementById('video');
    const overlay = document.getElementById('overlay');
    const ctx = overlay.getContext('2d');
    const startBtn = document.getElementById('start');
    const stopBtn = document.getElementById('stop');
    const snapshotBtn = document.getElementById('snapshot');
    const downloadBtn = document.getElementById('download');
    const toggleBoxesBtn = document.getElementById('toggleBoxes');
    const statusEl = document.getElementById('status');

    let model = null;
    let stream = null;
    let detectInterval = null;
    let showBoxes = true;

    // Resize overlay to match video size
    function resizeOverlay() {
      overlay.width = video.videoWidth;
      overlay.height = video.videoHeight;
    }

    // Draw detections
    function draw(predictions) {
      if (!ctx) return;
      ctx.clearRect(0,0,overlay.width,overlay.height);
      if (!predictions || predictions.length===0) return;

      predictions.forEach(pred => {
        const start = pred.topLeft || pred[0];
        const end = pred.bottomRight || pred[1];
        const probability = (pred.probability && pred.probability[0]) || pred.probability || 0;

        const x = start[0];
        const y = start[1];
        const w = end[0] - start[0];
        const h = end[1] - start[1];

        if (showBoxes) {
          ctx.lineWidth = Math.max(2, Math.round(Math.min(overlay.width, overlay.height) * 0.004));
          ctx.strokeStyle = 'rgba(6,182,212,0.95)';
          ctx.strokeRect(x, y, w, h);

          ctx.fillStyle = 'rgba(6,182,212,0.12)';
          ctx.fillRect(x, y + h - 22, 80, 20);

          ctx.fillStyle = '#e6eef6';
          ctx.font = '14px system-ui';
          ctx.fillText((probability*100).toFixed(1) + '%', x + 6, y + h - 6);
        }

        // draw landmarks if present
        if (pred.landmarks) {
          ctx.fillStyle = 'rgba(255,255,255,0.9)';
          pred.landmarks.forEach(pt => {
            ctx.beginPath();ctx.arc(pt[0], pt[1], 2, 0, Math.PI*2);ctx.fill();
          });
        }
      });
    }

    async function initModel() {
      statusEl.textContent = 'Status: loading model...';
      try {
        model = await blazeface.load();
        statusEl.textContent = 'Status: model loaded — ready';
      } catch (err) {
        statusEl.textContent = 'Status: failed to load model: ' + err.message;
        console.error(err);
      }
    }

    async function startCamera() {
      if (stream) return;
      try {
        stream = await navigator.mediaDevices.getUserMedia({video:{facingMode:'user'}, audio:false});
        video.srcObject = stream;
        await video.play();
        resizeOverlay();
        statusEl.textContent = 'Status: camera started';

        if (!model) await initModel();

        // Run detection loop
        detectInterval = requestAnimationFrame(detectLoop);
      } catch (err) {
        statusEl.textContent = 'Status: camera error — ' + err.message;
        console.error(err);
      }
    }

    function stopCamera() {
      if (detectInterval) cancelAnimationFrame(detectInterval);
      if (stream) {
        stream.getTracks().forEach(t => t.stop());
        stream = null;
        video.srcObject = null;
      }
      statusEl.textContent = 'Status: camera stopped';
      ctx.clearRect(0,0,overlay.width,overlay.height);
    }

    async function detectLoop() {
      if (!video || video.readyState < 2 || !model) {
        detectInterval = requestAnimationFrame(detectLoop);
        return;
      }

      resizeOverlay();

      try {
        const returnTensors = false; // easier to draw
        const predictions = await model.estimateFaces(video, returnTensors);
        draw(predictions);
        statusEl.textContent = `Status: ${predictions.length} faces detected`;
      } catch (err) {
        console.error('detect error', err);
      }

      detectInterval = requestAnimationFrame(detectLoop);
    }

    function takeSnapshot() {
      const w = overlay.width || 640;
      const h = overlay.height || 480;
      const canvas = document.createElement('canvas');
      canvas.width = w; canvas.height = h;
      const c = canvas.getContext('2d');
      // draw video then overlay
      c.drawImage(video, 0, 0, w, h);
      c.drawImage(overlay, 0, 0, w, h);
      return canvas;
    }

    snapshotBtn.addEventListener('click', () => {
      if (!video || !stream) return alert('Camera not running');
      const s = takeSnapshot();
      const w = window.open('');
      w.document.body.style.background = '#111';
      const img = new Image(); img.src = s.toDataURL('image/png'); img.style.maxWidth = '100%';
      w.document.body.appendChild(img);
    });

    downloadBtn.addEventListener('click', () => {
      if (!video || !stream) return alert('Camera not running');
      const s = takeSnapshot();
      s.toBlob(blob => {
        const url = URL.createObjectURL(blob);
        const a = document.createElement('a');
        a.href = url; a.download = 'snapshot.png';
        document.body.appendChild(a); a.click(); a.remove();
        URL.revokeObjectURL(url);
      });
    });

    startBtn.addEventListener('click', startCamera);
    stopBtn.addEventListener('click', stopCamera);
    toggleBoxesBtn.addEventListener('click', () => { showBoxes = !showBoxes; toggleBoxesBtn.textContent = showBoxes ? 'Toggle Boxes' : 'Toggle Boxes (off)'; });

    // Clean up when page is hidden/unloaded
    document.addEventListener('visibilitychange', () => {
      if (document.hidden) {
        // keep running; do nothing
      }
    });

    window.addEventListener('beforeunload', () => {
      if (stream) stopCamera();
    });

    // Auto-load model in background to reduce latency
    initModel();
  </script>
</body>
</html>
